# QCar Agentic AI: Video Demonstration Script

**[0:00-0:15] Introduction & Project Vision**

*   **(Scene: A dynamic shot of the QCar, perhaps a close-up of the sensors or the NVIDIA Jetson.)**
*   **Narrator (Voiceover):** "In the world of autonomous systems, the true test of intelligence is not just navigation, but interaction. Introducing the Agentic AI for QCar, a project that transforms a scaled research vehicle into an intelligent, interactive agent."
*   **(Text on screen: Agentic AI for QCar)**
*   **(Text on screen: Mimicking Advanced Research for Real-World Autonomy)**

**[0:15-0:45] Core Capabilities: See, Think, Act**

*   **(Scene: Show the web interface with the live camera feed (now 360-degree stitched), Lidar data, and status.)**
*   **Narrator:** "Our system is built on a robust architecture. The QCar, powered by an NVIDIA Jetson, handles real-time perception and control, while a powerful off-board server, running the Gemma 3n model, provides high-level intelligence."
*   **(Scene: Split screen showing the QCar moving and the web interface reflecting its actions.)**
*   **Narrator:** "This allows the QCar to not only see the world through its 360-degree vision and Lidar..."
*   **(Scene: The Lidar plot on the web UI dynamically changing as the QCar moves.)**
*   **Narrator:** "...but to understand it and react to its environment with advanced obstacle avoidance."

**[0:45-1:15] Live Demonstration: Autonomous Exploration & Obstacle Avoidance**

*   **(Scene: The user clicks the "Explore" button on the web interface.)**
*   **User (On-camera or voice command):** "QCar, start exploring."
*   **QCar (Audio response):** "Activating explore mode. I will now drive around and avoid obstacles."
*   **(Scene: The QCar navigates the environment, clearly avoiding obstacles using both Lidar and depth data. The Lidar visualization shows the obstacles, and the path visualization shows the agent's intended route.)**
*   **Narrator:** "Using a hierarchical planning system inspired by leading research, our agent combines A* for global pathfinding with a Vector Field Histogram for reactive, local obstacle avoidance, enhanced by depth sensor data."

**[1:15-1:45] Intelligent Interaction: Search, Track, and Describe**

*   **(Scene: The user places a yellow object in the QCar's path.)**
*   **User (Voice command):** "QCar, search for the yellow object."
*   **QCar (Audio response):** "Searching for the yellow object."
*   **(Scene: The QCar finds the object, stops, and centers it in the camera view.)**
*   **QCar (Audio response):** "Object detected. Describing the scene."
*   **(Scene: The AI's description is displayed as text on the screen as the audio plays.)**
*   **QCar (Generated Audio):** "I see a yellow toy car on a wooden floor, with a desk and chair in the background."
*   **User (Voice command):** "QCar, track the object."
*   **QCar (Audio response):** "Now tracking the object."
*   **(Scene: The user slowly moves the yellow object, and the QCar follows it.)**

**[1:45-2:15] Advanced Tracking: Face Following & Lane Keeping**

*   **(Scene: A person stands in front of the QCar.)**
*   **User (Voice command):** "QCar, track my face."
*   **QCar (Audio response):** "Activating face tracking. Following your face."
*   **(Scene: The QCar follows the person's face as they move.)**
*   **Narrator:** "Beyond simple color tracking, our agent can now identify and follow human faces, demonstrating advanced perception capabilities."
*   **(Scene: The QCar is placed on a track with visible lanes.)**
*   **User (Voice command):** "QCar, follow the lane."
*   **QCar (Audio response):** "Activating lane following."
*   **(Scene: The QCar autonomously follows the lane.)**
*   **Narrator:** "Furthermore, it can autonomously follow lanes, showcasing its ability to interpret road markings and maintain its position."

**[2:15-2:45] Seamless Control: Teleoperation & Voice Commands**

*   **(Scene: The user picks up a gamepad.)**
*   **User (Voice command):** "QCar, activate teleoperation."
*   **QCar (Audio response):** "Gamepad control activated."
*   **(Scene: The user drives the QCar using the gamepad, showing responsive control.)**
*   **Narrator:** "For situations requiring direct control, the system seamlessly switches to gamepad teleoperation. All modes can be controlled via our intuitive web interface or through natural language voice commands."

**[2:45-3:00] Conclusion & Future Vision**

*   **(Scene: A final, cinematic shot of the QCar.)**
*   **Narrator:** "The Agentic AI for QCar is more than just a self-driving car. It's a platform for research, a tool for learning, and a step towards a future where humans and intelligent agents collaborate seamlessly."
*   **(Text on screen: Google Gemma 3n Hackathon Submission)**
*   **(Text on screen: Your Name/Team Name)**